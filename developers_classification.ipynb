{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI916 - IA GL\n",
    "\n",
    "## Students\n",
    "\n",
    "| üéì Name | üìß Email | üè∑Ô∏è Student number |\n",
    "| --- | --- | --- | \n",
    "**Canta** Thomas | thomas.canta@etu.umontpellier.fr | 21607288\n",
    "**Fontaine** Quentin | quentin02.fontaine@etu.umontpellier.fr | 21614404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import glob\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import glob\n",
    "from git import Repo, Git\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fonction permettant de supprimer des colonnes dans un dataframe Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def delete_unused_columns(df):\n",
    "    columns_to_drop = [\"name\", \"followers\", \"commit_count_a\", \"source\", \"job\", \"name_without_spaces\", \"from\", \"to\",\n",
    "                       \"project\", \"index\", \"AddSM\",\"DelSM\",\"ChurnSM\",\"SumAddDelSM\",\"SumAddDel\"]\n",
    "\n",
    "    for column_to_drop in columns_to_drop:\n",
    "        if column_to_drop in df.columns :\n",
    "            df.drop(columns=[column_to_drop], inplace=True)\n",
    "\n",
    "    df[\"DiP\"] = df[\"DiP\"].round()\n",
    "    df[\"DiP\"].replace(0, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction permettant d'appliquer un logarithme sur des colonnes d'un dataframe Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def log_dataframe(df):\n",
    "\n",
    "    columns_4_log = [\"SumAddDelLOC\", \"DiP\", \"NoC\", \"SumAddDelF\",\n",
    "                     \"SumAddDelSAM\", \"AddLOC\", \"DelLOC\", \"AddSAM\", \"DelSAM\"]\n",
    "\n",
    "    for column in columns_4_log:\n",
    "        df[column] = np.log(df[column] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scores the classifier using a k-fold (here a Stratified 4-fold with shuffle)\n",
    "Synthetic data are created to train the classifier for each fold.\n",
    "Real data are used to compute measures for the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) R√©cup√©ration des m√©triques de BroadleafCommerce\n",
    "\n",
    "Nous travaillerons avec les versions majeures et mineures (voir [semantic versioning](https://semver.org/lang/fr/)) du projet BroadleafCommerce disponible sur GitHub : [https://github.com/BroadleafCommerce/BroadleafCommerce](https://github.com/BroadleafCommerce/BroadleafCommerce). Pour cela, nous allons cloner le d√©p√¥t puis r√©cup√©rer les tags des versions et les filtrer par une expression r√©guli√®re. Puis, pour chacun de ces tags, \"checkouter\" la version correspondante. Nous lancerons ensuite l'extraction des m√©triques √† l'aide de l'application Java : ck ([https://github.com/mauricioaniche/ck](https://github.com/mauricioaniche/ck)). Cette application cr√©√©e par Maur√≠cio Aniche est d√©di√©e √† l'extraction de plusieurs m√©triques logicielles dont le nombre de lignes de code que nous utiliserons plus tard. \n",
    "\n",
    "Dans ce TP, nous allons extraire \"manuellement\" m√©triques mais, les plateformes d'int√©gration continue comme Jenkins ou les outils d'analyse statique comme SonarQube permettent √©galement de calculer des m√©triques de mani√®re automatique √† chaque version releas√©e ou commit√©e sur votre syst√®me de gestion de versions. \n",
    "\n",
    "\n",
    "Pour notre cas d'√©tude, nous allons : \n",
    "\n",
    "1. Utiliser le package GitPython et sa [documentation](https://gitpython.readthedocs.io/en/stable/)) pour :\n",
    "\n",
    "* Cloner le d√©p√¥t Github de BroadleafCommerce √† l'endroit indiqu√© par la variable <code> PATH_TO_REPO </code> √† l'aide de la m√©thode <code> Repo.clone_from </code>\n",
    "* Cr√©er un objet <code> Repo </code> qui vous permettra de r√©cup√©rer les tags des versions\n",
    "* Cr√©er un objet <code> Git </code> qui vous permettra de \"checkouter\" la version d√©sir√©e\n",
    "\n",
    "2.¬†R√©cup√©rer la liste des tags du d√©p√¥t √† l'aide de l'objet <code> Repo </code>.\n",
    "\n",
    "3. It√©rer sur la liste des tags, o√π pour chaque tag vous allez : \n",
    "\n",
    "* V√©rifier par une regexp que l'on se situe sur des tags ayant la forme <code> broadleaf-X.Y.0.GA </code> o√π <code> X </code> et <code> Y </code> peuvent varier entre 0 et 9 et o√π le tag a une taille fixe (utilisation de ^ et $ pour mat√©rialiser le d√©but et la fin de chaine de caract√®res)\n",
    "* V√©rifier que l'on ne va pas extraire les m√©triques d'une version d√©j√† pr√©sente dans le dossier <code> ck_metrics </code>\n",
    "* **/!\\ Une fois ces v√©rifications effectu√©es,** checkouter la version d√©sir√©e √† l'aide du tag\n",
    "* Lancer l'extraction des m√©triques √† l'aide de l'instruction python suivante : <code> subprocess.run([\"java\", \"-jar\", \"ck.jar\", \"..\" + os.sep + \"BroadleafCommerce\"]) </code>\n",
    "* Renommer le fichier <code> class.csv </code> en <code> class_[tag].csv </code> et supprimer les fichiers <code> variable.csv, methode.csv, field.csv </code> cr√©√©s par ck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIT_REPO = \"https://github.com/BroadleafCommerce/BroadleafCommerce.git\"\n",
    "PATH_TO_REPO = \".\"+os.sep+\"BroadleafCommerce\"\n",
    "\n",
    "#Cr√©er les objets Git et repo ici avant l'instruction change directory\n",
    "REPO = Repo.clone_from(GIT_REPO, PATH_TO_REPO)\n",
    "GIT = REPO.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©cup√©ration des tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['broadleaf-1.5.0-GA', 'broadleaf-1.6.0-GA', 'broadleaf-2.0.0-GA', 'broadleaf-2.1.0-GA', 'broadleaf-2.2.0-GA', 'broadleaf-2.3.0-GA', 'broadleaf-2.4.0-GA', 'broadleaf-3.0.0-GA', 'broadleaf-3.1.0-GA', 'broadleaf-4.0.0-GA', 'broadleaf-4.1.0-GA', 'broadleaf-5.0.0-GA', 'broadleaf-5.1.0-GA', 'broadleaf-5.2.0-GA', 'broadleaf-6.0.0-GA', 'broadleaf-6.1.0-GA', 'broadleaf-6.2.0-GA']\n"
     ]
    }
   ],
   "source": [
    "regPattern = \"^broadleaf-[0-9].[0-9].0-GA$\"\n",
    "tags = []\n",
    "\n",
    "for tag in REPO.tags:\n",
    "    if re.match(regPattern, str(tag)):\n",
    "        tags.append(str(tag));\n",
    "\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en commun avec les tags existants dans *ck_metrics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['broadleaf-6.1.0-GA', 'broadleaf-6.0.0-GA', 'broadleaf-1.5.0-GA', 'broadleaf-5.2.0-GA', 'broadleaf-6.2.0-GA']\n"
     ]
    }
   ],
   "source": [
    "wd_notebook = os.getcwd()\n",
    "os.chdir(\".\" + os.sep + \"ck_metrics\")\n",
    "\n",
    "#Placer l'ensemble du code n√©cessaire √† l'extraction ici\n",
    "regPattern = \"(class_)(broadleaf-[0-9].[0-9].[0-9]-GA)(.csv)\"\n",
    "existingVersion = []\n",
    "for file in os.listdir():\n",
    "    match = re.match(regPattern, file)\n",
    "    if match:\n",
    "        existingVersion.append(match.group(2))\n",
    "\n",
    "tags = list(set(tags) - set(existingVersion))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des m√©triques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log4j:WARN No appenders could be found for logger (com.github.mauricioaniche.ck.CK).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n",
      "log4j:WARN No appenders could be found for logger (com.github.mauricioaniche.ck.CK).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n",
      "log4j:WARN No appenders could be found for logger (com.github.mauricioaniche.ck.CK).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n",
      "log4j:WARN No appenders could be found for logger (com.github.mauricioaniche.ck.CK).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n",
      "log4j:WARN No appenders could be found for logger (com.github.mauricioaniche.ck.CK).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction done!\n"
     ]
    }
   ],
   "source": [
    "for tag in tags:\n",
    "    GIT.checkout(tag)\n",
    "    subprocess.run([\"java\", \"-jar\", \"ck.jar\", \"..\" + os.sep + \"BroadleafCommerce\"])\n",
    "    os.rename(\"class.csv\", \"class_\" + tag + \".csv\")\n",
    "    os.remove(\"field.csv\")\n",
    "    os.remove(\"method.csv\")\n",
    "    os.remove(\"variable.csv\")\n",
    "\n",
    "print(\"Extraction done!\")\n",
    "os.chdir(wd_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Utilisation du classifieur de d√©veloppeurs (Random Forest)\n",
    " \n",
    "Nous allons maintenant utiliser le classifieur de d√©veloppeurs sauvegard√© sous le nom \"classifier_rf.pkl\". \n",
    "Pour cela nous allons charger le classifieur √† l'aide de <code> joblib.load </code> ([documentation](https://joblib.readthedocs.io/en/latest/generated/joblib.load.html))\n",
    "\n",
    "2. Nous allons utiliser les m√©triques (23) associ√©es √† des d√©veloppeurs, celles-ci sont stock√©es dans le dossier <code> metrics_by_dev </code>. Chaque fichier de ce dossier est nomm√© en fonction de la version sur laquelle les m√©triques ont √©t√© extraites. Nous allons donc it√©rer sur la **liste de ces fichiers ordonn√©e par ordre alphanum√©rique**. \n",
    "\n",
    "4. Pour chaque fichier CSV, l'ouvrir avec Pandas en tant que Dataframe via la fonction : <code> pd.read_csv </code> ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html))\n",
    "\n",
    "3. Ces m√©triques sont √† l'√©tat \"brut\" dans les fichiers, c'est-√†-dire qu'elles ont des √©chelles et des unit√©s diff√©rentes. Le classifieur Random Forest que nous avons entrain√© lui, ne travaille qu'avec des variables comprises dans [-1;1]. Ici, il va donc falloir faire une mise √† l'√©chelle des variables √† l'aide d'un scaler de Scikit-Learn : <code> MinMaxScaler </code> ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)). De plus, afin de r√©duire les √©carts de valeurs sur certaines variables nous allons appliquer un logarithme sur 11 de ces derni√®res √† l'aide de la fonction  <code> log_dataframe </code> de ce Notebook.\n",
    "\n",
    "5. Pr√©dire ensuite la cat√©gorie des d√©veloppeurs (\"NSSE\" ou \"SSE\") puis la stocker dans le dictionnaire <code> dict_classified_dev </code>. Faire un affichage √† l'aide print pour visualiser l'√©volution du nombre de d√©voloppeurs dans chaque cat√©gorie au fur et √† mesure des versions.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'classifier_rf.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11479/1554417114.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Placer la suite du code ici\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classifier_rf.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"metrics_by_dev\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/M2GL/HAI916I/tp/tp6/TP-Master-MTP-GL-IA4GL/venv/lib/python3.9/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'classifier_rf.pkl'"
     ]
    }
   ],
   "source": [
    "dict_classified_dev = {'SSE' : [], 'NSSE' : []}\n",
    "list_versions = []\n",
    "\n",
    "#Placer la suite du code ici\n",
    "joblib.load(\"classifier_rf.pkl\")\n",
    "\n",
    "os.chdir(\".\" + os.sep + \"metrics_by_dev\")\n",
    "for file in os.listdir():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Extraction du nombre total de lignes de code depuis les fichiers CSV\n",
    "\n",
    "Nous avons class√© les d√©veloppeurs par cat√©gorie pour chaque version de BroadleafCommerce. \n",
    "L'√©tape suivante est d'extraire le nombre total de ligne de code pour chaque version de BroadleafCommerce. Pour cela chacun des fichiers tri√©s par ordre alphanum√©rique croissant doit √™tre ouvert avec Pandas. Vous devez ensuite faire la somme de la colonne \"loc\" des fichiers et l'ajouter √† la liste <code> loc_by_versions </code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liste o√π ajouter les loc de chaque version \n",
    "loc_by_versions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Trac√© du graphique du nombre de d√©veloppeurs SSE et nombre de lignes de code par version de BroadleafCommerce\n",
    "\n",
    "L'objectif ici est de tracer √† l'aide du package matplotlib ([documentation](https://matplotlib.org/stable/contents.html)) un graphique √† 3 axes comme montr√© dans la figure d'exemple ci-dessous. \n",
    "\n",
    "![√âvolution du nombre de d√©veloppeurs SSE vs LOC](plot_sse_vs_loc_by_version.png)\n",
    "\n",
    "En tra√ßant cette figure vous devriez observer une particularit√© commune aux deux courbes, faite part de cette observation dans la case textutelle ci-desssous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOV0lEQVR4nO3cf6jdd33H8eeriZn0WOtYECSJpmMpGOrALtTun7Vb60jzR/KHQxoorlIacFTGFKHgH0r9y8kcCMV6x0qnYGv0D7lgJQNXKYgpCessTUrLXSxNolBXa/+4mda7vffHOfGe3t37Od8053tOmjwfcOB8v9/P/X4+58O979f9/jqpKiRJ2shV8x6AJOnSZlBIkpoMCklSk0EhSWoyKCRJTQaFJKlpYlAkeTjJy0me3WB7knwlyVKSZ5LcOP1hSpK66KNmdzmieATY29h+B7Br9DoEfLXDPiVJ/XiEKdfsiUFRVU8Cv2w0OQB8vYaOAu9K8p5J+5UkTV8fNXvzFMa1DTg9tnxmtO7naxsmOcQwwQD+5Oqrr55C95J05Th37lwB/z62aqGqFi5gF51r9nnTCIrORh9mAWAwGNTy8vIsu5ekt7wk/11Ve2bZ5zTuejoL7Bhb3j5aJ0m69FxwzZ5GUCwCHxtdSb8ZeK2qNjyEkSTN1QXX7ImnnpI8CtwKbE1yBvgc8DaAqnoIeBzYBywB54CPX8wnkCS9eX3U7Mzra8a9RiFJFy7JuaoazLJPn8yWJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLU1CkokuxN8nySpST3r7P9vUmeSPJ0kmeS7Jv+UCVJk/RRr1NVkzrdBLwAfBg4AxwDDlbVybE2C8DTVfXVJLuBx6tqZ2u/g8GglpeXJ41PkjQmybmqGmywrZd63eWI4iZgqapOVdXrwGPAgTVtCnjn6P21wM867FeSNF291OvNHTreBpweWz4DfGhNm88D/5rkk8AAuH29HSU5BBwC2LJlS4euJUlrbE5yfGx5oaoWRu+nVq/HTeti9kHgkaraDuwDvpHk/+27qhaqak9V7dm8uUtGSZLWWDlfR0evhck/8gad6vW4LkFxFtgxtrx9tG7cPcBhgKr6MfB2YGvHQUuSpqOXet0lKI4Bu5Jcl2QLcCewuKbNS8BtAEneP+r4Fx32LUmanl7q9cSgqKoV4D7gCPAccLiqTiR5IMn+UbNPA/cm+QnwKHB3TbqdSpI0VX3V64m3x/bF22Ml6cK1bo/ti09mS5KaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVJTp6BIsjfJ80mWkty/QZuPJjmZ5ESSb053mJKkLvqo16mqSZ1uAl4APgycAY4BB6vq5FibXcBh4C+q6tUk766ql1v7HQwGtby8PGl8kqQxSc5V1WCDbb3U6y5HFDcBS1V1qqpeBx4DDqxpcy/wYFW9CjCpU0lSL3qp112CYhtwemz5zGjduOuB65P8KMnRJHvX21GSQ0mOJzm+srLSoWtJ0hqbz9fR0evQ2Lap1es3dHjxY/7dfnYBtwLbgSeTfKCqfjXeqKoWgAUYnnqaUt+SdCVZqao9F/Hzner1uC5HFGeBHWPL20frxp0BFqvqt1X1U4bnyHZ1H7ckaQp6qdddguIYsCvJdUm2AHcCi2vafJdhOpFkK8NDm1Md9i1Jmp5e6vXEoKiqFeA+4AjwHHC4qk4keSDJ/lGzI8ArSU4CTwCfqapXOn4wSdIU9FWvJ94e2xdvj5WkC9e6PbYvPpktSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpqVNQJNmb5PkkS0nub7T7SJJKsmd6Q5QkddVHvZ4YFEk2AQ8CdwC7gYNJdq/T7hrgb4GnJu1TkjR9fdXrLkcUNwFLVXWqql4HHgMOrNPuC8AXgV936ViSNHW91OsuQbENOD22fGa07neS3AjsqKrvtXaU5FCS40mOr6ysdBmfJOmNNp+vo6PXobFtU6vXb+jwooY77PQq4MvA3ZPaVtUCsAAwGAzqYvuWpCvQSlW9qevAF1Kvx3U5ojgL7Bhb3j5ad941wA3AD5O8CNwMLHpBW5Jmrpd63SUojgG7klyXZAtwJ7B4fmNVvVZVW6tqZ1XtBI4C+6vqeId9S5Kmp5d6PTEoqmoFuA84AjwHHK6qE0keSLL/zX8eSdI09VWvUzWfSwWDwaCWl5fn0rckvVUlOVdVg1n26ZPZkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktTUKSiS7E3yfJKlJPevs/1TSU4meSbJD5K8b/pDlSRN0ke9nhgUSTYBDwJ3ALuBg0l2r2n2NLCnqv4Y+A7w910+kCRpevqq112OKG4ClqrqVFW9DjwGHBhvUFVPVNW50eJRYHuH/UqSpquXet0lKLYBp8eWz4zWbeQe4PvrbUhyKMnxJMdXVlY6dC1JWmPz+To6eh0a2za1ev2GDt/cONeX5C5gD3DLeturagFYABgMBjXNviXpCrFSVXsudieT6vW4LkFxFtgxtrx9tG5tp7cDnwVuqarfdBuqJGmKeqnXXU49HQN2JbkuyRbgTmBxTacfBL4G7K+qlzvsU5I0fb3U64lBUVUrwH3AEeA54HBVnUjyQJL9o2ZfAt4BfDvJfyRZ3GB3kqSe9FWvUzWfSwWDwaCWl5fn0rckvVUlOVdVg1n26ZPZkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmjoFRZK9SZ5PspTk/nW2/16Sb422P5Vk59RHKkmaqI96PTEokmwCHgTuAHYDB5PsXtPsHuDVqvoj4B+BL3b4PJKkKeqrXnc5orgJWKqqU1X1OvAYcGBNmwPAv4zefwe4LUk67FuSND291OvNHTreBpweWz4DfGijNlW1kuQ14A+A/xpvlOQQcGhs+VyH/q8Em4GVeQ/iEuFcrHIuVjkXq65OcnxseaGqFkbvp1avx3UJiqkZfZgFgCTHq2rPLPu/VDkXq5yLVc7FKudi1Tzmosupp7PAjrHl7aN167ZJshm4FnhlGgOUJHXWS73uEhTHgF1JrkuyBbgTWFzTZhH469H7vwL+raqqw74lSdPTS72eeOppdA7rPuAIsAl4uKpOJHkAOF5Vi8A/A99IsgT8cjS4SRYmN7liOBernItVzsUq52LVhnPRV72O//hLklp8MluS1GRQSJKaeg8Kv/5jVYe5+FSSk0meSfKDJO+bxzhnYdJcjLX7SJJKctneGtllLpJ8dPS7cSLJN2c9xlnp8Dfy3iRPJHl69Heybx7j7FuSh5O8nOTZDbYnyVdG8/RMkht7HVBV9fZieDHlP4E/BLYAPwF2r2nzN8BDo/d3At/qc0zzenWciz8Hrh69/8SVPBejdtcATwJHgT3zHvccfy92AU8Dvz9afve8xz3HuVgAPjF6vxt4cd7j7mku/gy4EXh2g+37gO8DAW4GnupzPH0fUfj1H6smzkVVPVFV559WP8rwHujLUZffC4AvMPweml/PcnAz1mUu7gUerKpXAarq5RmPcVa6zEUB7xy9vxb42QzHNzNV9STDO5I2cgD4eg0dBd6V5D19jafvoFjvcfJtG7WpqhXg/OPkl5suczHuHob/MVyOJs7F6FB6R1V9b5YDm4MuvxfXA9cn+VGSo0n2zmx0s9VlLj4P3JXkDPA48MnZDO2Sc6H15KLM9Cs81E2Su4A9wC3zHss8JLkK+DJw95yHcqnYzPD0060MjzKfTPKBqvrVPAc1JweBR6rqH5L8KcPnAW6oqv+d98AuZ30fUfj1H6u6zAVJbgc+C+yvqt/MaGyzNmkurgFuAH6Y5EWG52AXL9ML2l1+L84Ai1X126r6KfACw+C43HSZi3uAwwBV9WPg7cDWmYzu0tKpnkxL30Hh13+smjgXST4IfI1hSFyu56FhwlxU1WtVtbWqdlbVTobXa/ZX1fH1d/eW1uVv5LsMjyZIspXhqahTMxzjrHSZi5eA2wCSvJ9hUPxipqO8NCwCHxvd/XQz8FpV/byvzno99VT9ff3HW07HufgS8A7g26Pr+S9V1f65DbonHefiitBxLo4Af5nkJPA/wGeq6rI76u44F58G/inJ3zG8sH335fiPZZJHGf5zsHV0PeZzwNsAquohhtdn9gFLwDng472O5zKcY0nSFPlktiSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJavo/EZ9TR375znkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "#Cr√©ation d'un deuxi√®me axe Y \n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Cr√©ation d'un estimateur du nombre de d√©veloppeurs exp√©riment√©s en fonction de la taille du projet (LoC)\n",
    "\n",
    "\n",
    "Nous avons maintenant l'ensemble des donn√©es permettant de cr√©er un estimateur du nombre de d√©veloppeurs exp√©riment√©s en fonction du nombre de ligne de code du projet. \n",
    "Pour ce faire, nous allons mettre en oeuvre un estimateur bas√© sur une r√©gression lin√©aire : <code> LinearRegression </code> ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)). Cet estimateur utilise la m√©thode des moindres carr√©s afin d'ajuster une droite d'√©quation *ax+b+e* o√π *a* est le coefficient directeur, *b* l'ordonn√©e √† l'origine et *e* l'erreur li√©e aux moindres carr√©s. \n",
    "\n",
    "Pour cela nous allons : \n",
    "1. Cr√©er un objet LinearRegression et l'ajuster sur <code> X </code> et <code> y </code> √† l'aide de la m√©thode <code> fit </code>.\n",
    "2. Afficher le coefficient de r√©gression sur <code> X </code> et <code> y </code>.\n",
    "3. D√©terminer le coefficient de d√©termination lin√©aire avec la fonction <code> r2_score </code> ([documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score)) qui mesure l'ajustement entre les pr√©diction du classifieur sur les donn√©es <code> X </code> par rapport aux sorties <code> y </code>, plus il proche de 1 meilleures sont les pr√©dictions. \n",
    "4. Pr√©dire le nombre de d√©veloppeurs exp√©riment√©s SSE pour 150000, 180000 et 200000 lignes de code. \n",
    "5. Tracer un graphique semblable √† la figure d'exemple ci-desssous :\n",
    "\n",
    "![](plot_sse_loc_prediction.png)\n",
    "\n",
    "Les points noirs sont les donn√©es d√©j√† connues √† savoir le nombre de d√©veloppeurs exp√©riment√©s et le nombre de lignes de code pour chaque version. Les point rouges correspondent aux trois valeurs pr√©dites pour 150000, 180000 et 200000 lignes. La droite bleu est la droite de r√©gression. Pour tracer ce graphique vous pouvez vous inspirer de cet [exemple Scikit-Learn ](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py). \n",
    "\n",
    "Voil√† vous √™tes maintenant capable de pr√©dire vos besoins en ressources humaines en fonction de la taille de votre projet :) ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valeurs X et y √† utiliser pour entrainer et √©valuer le r√©gresseur\n",
    "X = np.array(loc_by_versions).reshape(-1,1)\n",
    "y = np.array(dict_classified_dev[\"SSE\"])\n",
    "\n",
    "#PLacer la suite du code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus\n",
    "\n",
    "Jusque l√† nous avons utilis√© un classifieur Random Forest d√©j√† entrain√© puis sauvegard√© au format Pickle (s√©rialisation). Dans le bloc de code ci-dessous vous trouverez le code qui a permis la cr√©ation de ce classifieur. \n",
    "\n",
    "Ce code est d√©coup√© en plusieurs parties:\n",
    "\n",
    "* Ouverture du CSV contenant les d√©veloppeurs et leurs m√©triques avec Pandas\n",
    "* Suppresssion des colonnes non utilis√©es pour la classification\n",
    "* Transformation des variables (logarithme et mise √† l'√©chelle)\n",
    "* Cr√©ation de l'objet permettant de g√©n√©rer des donn√©es synth√©tiques. Les donn√©es synth√©tiques permettent de contrebalancer le fait que nous n'ayons que peu de donn√©es dans la classe des d√©veloppeurs exp√©riment√©s. \n",
    "* Cr√©ation du classifieur ici un random forest\n",
    "* √âvaluation du classifieur via 4-fold stratifi√© ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html?highlight=stratifiedkfold#sklearn.model_selection.StratifiedKFold))\n",
    "* G√©n√©ration de donn√©es synth√©tiques sur l'ensemble du jeu de donn√©es puis entrainement du mod√®le\n",
    "* Sauvegarde du mod√®le au format pickle\n",
    "\n",
    "Vous pouvez modifier plusieurs choses qui vont influer sur la qualit√© de votre classifieur :  \n",
    "- Les variables utilis√©es. Nous utilisons ici 23 m√©triques. Vous pouvez en supprimer dans le dataframe Pandas et constater l'effet. \n",
    "- Le scaler utilis√©, ici un MinMax pour mettre les variables dans l'intervalle [-1,1] ([documentation sur les types de scaler](https://www.datacorner.fr/feature-scaling/))\n",
    "- Le type de classifieur utilis√© (ici Random Forest) et ses param√®tres. Vous pouvez choisir un autre classifieur parmis ceux fournis par le package Scikit Learn ([documentation](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py))\n",
    "- L'utilisation ou non de la g√©n√©ration de donn√©es synth√©tiques. \n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Returns labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels(df):\n",
    "    df.loc[df['job'] == \"SA\", 'job'] = \"SSE\"\n",
    "    df.loc[df['job'] != \"SSE\", 'job'] = \"NSSE\"\n",
    "\n",
    "    return df[\"job\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scales data according to the scaler given as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scaling(scaler, X):\n",
    "    return scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creates synthetic data with original data using smote method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_synthetic_data(smote, X_scaled, y):\n",
    "    return smote.fit_resample(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train the classifier with synthetic data an create a classification report on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_classification_report(classifier, X_synthetic, y_synthetic, X_scaled, y):\n",
    "    classifier.fit(X_synthetic, y_synthetic)\n",
    "    print(classification_report(y, classifier.predict(X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def stratifiedKFold_scoring(classifier, X_scaled, y, smote = None):\n",
    "    kf = StratifiedKFold(n_splits=4, shuffle=False)#, random_state=0)\n",
    "    print(\"===> Start kfold <===\")\n",
    "    scores = {\"F1\": {\"values\" : []}, \"Recall\": {\"values\" : []},\n",
    "              \"Precision\": {\"values\" : []}, \"Balanced\\nAccuracy\" : {\"values\" : []}}\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X_scaled, y), 1):\n",
    "        print(\"=> Fold : \",fold)\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train = X_scaled[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X_scaled[test_index]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        if smote is not None:\n",
    "            X_train_synthetic, y_train_synthetic = smote.fit_resample(X_train, y_train)\n",
    "            classifier.fit(X_train_synthetic, y_train_synthetic)\n",
    "        else:\n",
    "            classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=\"SSE\")\n",
    "        recall = recall_score(y_test, y_pred, pos_label=\"SSE\")\n",
    "        precision = precision_score(y_test, y_pred, pos_label=\"SSE\")\n",
    "        accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "        scores[\"F1\"][\"values\"].append(f1)\n",
    "        scores[\"Recall\"][\"values\"].append(recall)\n",
    "        scores[\"Precision\"][\"values\"].append(precision)\n",
    "        scores[\"Balanced\\nAccuracy\"][\"values\"].append(accuracy)\n",
    "\n",
    "    for key in scores:\n",
    "        scores[key][\"values\"] = np.array(scores[key][\"values\"])\n",
    "        scores[key][\"mean\"] = np.mean(scores[key][\"values\"])\n",
    "        scores[key][\"std\"] = np.std(scores[key][\"values\"])\n",
    "        scores[key][\"ci95\"] = np.std(scores[key][\"values\"]) * 2\n",
    "\n",
    "        print(key, \"mean :%0.4f\" % scores[key][\"mean\"])\n",
    "        print(key, \"std : %0.4f\" % scores[key][\"std\"])\n",
    "        print(key, \"95%% Confidence Interval +/- %0.4f\" % (scores[key][\"ci95\"]))\n",
    "        print()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Start kfold <===\n",
      "=> Fold :  1\n",
      "=> Fold :  2\n",
      "=> Fold :  3\n",
      "=> Fold :  4\n",
      "F1 mean :0.7689\n",
      "F1 std : 0.0263\n",
      "F1 95% Confidence Interval +/- 0.0525\n",
      "\n",
      "Recall mean :0.7538\n",
      "Recall std : 0.0800\n",
      "Recall 95% Confidence Interval +/- 0.1601\n",
      "\n",
      "Precision mean :0.7937\n",
      "Precision std : 0.0414\n",
      "Precision 95% Confidence Interval +/- 0.0828\n",
      "\n",
      "Balanced\n",
      "Accuracy mean :0.8603\n",
      "Balanced\n",
      "Accuracy std : 0.0343\n",
      "Balanced\n",
      "Accuracy 95% Confidence Interval +/- 0.0687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_dev_anonymized.csv\")\n",
    "y = get_labels(df)\n",
    "\n",
    "delete_unused_columns(df)\n",
    "\n",
    "log_dataframe(df)\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "X = df\n",
    "X_scaled = scaling(scaler, X)\n",
    "\n",
    "#Instanciation du g√©n√©rateur de donn√©es synth√©tiques √† l'aide de la m√©thode k-means SMOTE\n",
    "smote = KMeansSMOTE(sampling_strategy='minority', random_state=9090)\n",
    "#Cr√©ation du classifieur RF\n",
    "classifier = RandomForestClassifier(criterion='gini', max_depth=None, max_features='log2', n_estimators=75, random_state=0)\n",
    "\n",
    "#√âvaluation du classifieur √† l'aide d'un 4-fold stratifi√©\n",
    "stratifiedKFold_scoring(classifier, X_scaled, y, smote = smote)\n",
    "\n",
    "#G√©n√©ration de donn√©es synth√©tiques sur l'ensemble des donn√©es\n",
    "X_synthetic, y_synthetic = smote.fit_resample(X_scaled, y)\n",
    "#Entrainement du classifieur sur les donn√©es synth√©tiques\n",
    "classifier.fit(X_synthetic, y_synthetic)\n",
    "#Sauvegarde du classifieur (s√©rialisation) \n",
    "pickle.dump(classifier, open(\"classifier_rf.pkl\", 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b972025ffaeb9fad2e6c47485e66bc7f129e1b41ab4934c78195a6e21efd40ea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
